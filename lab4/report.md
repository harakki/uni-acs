# Отчет по лабораторной работе 4

### Шипилов Дементий, ИП-215

## Балансировка нагрузки *nginx*

Для распределения нагрузки между серверами с использованием фронтенд-сервера *nginx*, необходимо в конфигурационном файле объявить бекенд-сервера, между которыми необходима балансировка нагрузки и метод распределения нагрузки. Например:

```conf
upstream web-address {
    server 10.10.10.1;
    server 10.10.10.2;
    ...
}

server {
    location / {
        proxy_pass http://web-address;
    }
}
```

| Алгоритм | Способ активации | Плюсы | Минусы |
|---|---|---|---|
| Round Robin | Используется, если инной алгоритм не указан | Хорошо масштабируется, равномерно распределяет нагрузку между приложениями и не нагружает систему | Не учитывает разную производительность серверов и текущую загрузку приложений. |
| Least Connections | Указание алгоритма для списка серверов `upstream web_address { least_conn; }` | Распределяет нагрузку на приложения с наименьшим количеством активных соединений | Может привести к неравномерному распределению нагрузки при большом количестве медленных клиентов |
| Weighted Round Robin | Указание веса для каждого сервера `server 10.10.10.1 weight=1;` | Даёт возможность задавать различные веса для серверов, отражающие их производительность | Не учитывает текущую загрузку приложений и требуется ручная настройка весов |
| Weighted Least Connections | Указание алгоритма в списке серверов и веса каждого сервера | Учитывает разную производительность серверов, опираясь на количество активных соединений и распределяет нагрузку пропорционально весам и количеству соединений | Требуется ручная настройка весов |
| IP Hash | Указание алгоритма `upstream web_address { least_conn; }` | Привязывает клиента к определенному IP-адресу и обеспечивает сохранение состояния сеанса клиента на одном сервере | Не учитывает текущую загрузку приложений, не учитывает производительность серверов и может привести к неравномерному распределению нагрузки при большом количестве клиентов с одинаковым IP-адресом |

> Для автоматического управления распределением клиентов между серверами в случае падения одного из них можно установить параметры `max_fails` и `fail_timeout`, отвечающие за **количество пропущенных ответов на запрос** и **время, за которое необходимо, чтобы запросы не были удовлетворены** соответственно.

## Балансировка нагрузки *traefik*

Для распределения нагрузки с использованием *traefik* необходимо при инициализации контейнера, с помощью команд *docker-compose*, установить необходимые флаги.

> В случае, когда автоматическое объявление новых контейнеров в сети отключено, при этом необходимо их объявить, необходимо в файле *docker-compose* добавить метки, указывающие *traefik*, как необходимо обойтись с контейнером
> 
> ```yaml
> container:
>   labels:
>     # Проксирование через Traefik
>     - "traefik.enable=true"
>     # Объявление веб-адреса контейнера
>     - "traefik.http.routers.web.rule=Host(`web-address`)"
>     # Объявление разрешенных точек входа
>     - "traefik.http.routers.web.entrypoints=http"
> ```

## Балансировка нагрузки *lvs/ipvs*

Для распределения нагрузки с использованием *ipvsadm*, использующем модули ядра Linux `ip_vs`, необходимо активировать нужные модули и запустить балансировку нагрузки на виртуальном сервисе

```shell
# Активация модулей яздра Linux
modprobe ip_vs
modprobe ip_vs_rr
modprobe ip_vs_wrr
modprobe ip_vs_sh

# Активация перенаправления запросов между бэкенд-серверами
sysctl -w net.ipv4.ip_forward=1

# Создание виртуального сервиса, использующего метод Round Robin и пересылку запросов с помощью NAT
ipvsadm -A -t frontend:80 -s rr

# Добавление бэкенд-сервера в балансировщик нагрузки
ipvsadm -a -t frontend:80 -r backend:80 -m
```
